# ruff: noqa: RUF001

from typing import Sequence

from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from openai import OpenAI

from notice_api.core.config import settings

OpenAIClient = OpenAI(api_key=settings.OPENAI_API_KEY)

llm = ChatOpenAI(
    model="gpt-3.5-turbo-16k", temperature=0.3, api_key=settings.OPENAI_API_KEY
)

llm_stream = ChatOpenAI(
    model="gpt-3.5-turbo-16k",
    temperature=0.3,
    api_key=settings.OPENAI_API_KEY,
    streaming=True,
)

cleaning_template = """
- Eliminate redundant words from the following raw transcript
- The content of the raw transcript will be marked as such: RAW TRANSCRIPT ```(raw transcript content)```
- Words are considered redundant if it satisfy one of the following conditions:
    - 1. Time stamps
    - 2. Markings or abbriviations which seem to be generated by other speach-to-text/caption services. For example, "WEBVTT"

- RAW TRANSCRIPT ```{raw_transcript}```
"""

note_generation_template = """
- task：Your job is to generate bulletpoint notes from the provided transcript
    - input：
        - the latest transcript
        - the content of the transcript will be marked as such: transcript ```(transcript content)```
    - output：
        - represent the whole trancript content as bulletpoints without lost information
        - the bulletpoints should strictly follow the chronological order of the input transcript
        - output the bulletpoints using markdown
        - each content of the bulletpoints can only be one of the following: a single sentence, keyword(s), words used for formatting
        - if a bulletpoint sentence is too long, split it into multiple sub-bulletpoints
        - the whole output should contain at least 1500 characters and be as detailed as possible
        - only output the bulletpoints and sub-bulletpoints texts
        - don't use the example output word for word
        - output format: "
            - <bulletpoint 1>
            - <bulletpoint 2>
                - <sub-bulletpoint 2-1>
                - <sub-bulletpoint 2-2>
                ...
            - <bulletpoint 3>
            ...
        "
        - example output: "
- Introduction to Algorithms
    - Lecture two
    - Erik Demaine loves algorithms
- Data Structures
    - Sequences, sets, linked lists, dynamic arrays
    - Simple data structures
    - Beginning of several data structures
- Interface vs Data Structure
    - Interface specifies what you want to do
    - Data structure specifies how to do it
- Operations on Data Structures
    - Storing data
    - Specifying operations and their meanings
    - Algorithms for supporting operations
- Two main interfaces: set and sequence
    - Set: maintaining data in sorted order, searching for a key
    - Sequence: maintaining a particular sequence, storing n things
- Two main approaches: arrays and pointers
- Static Sequence Interface
    - Number of items doesn't change
    - Operations: build, length, iteration, get, set
- Static Array
    - Solution to the static sequence interface problem
    - No static arrays in Python, only dynamic arrays
- Word RAM model of computation
        "

- transcript ```{transcript}```
"""


def generate_note_langchain(transcript: str | Sequence[str], usernote: str) -> str:
    # 去除冗言贅字
    prompt_template = PromptTemplate(
        input_variables=["raw_transcript"], template=cleaning_template
    )
    chain1 = LLMChain(llm=llm, prompt=prompt_template)

    # 整理成條列式
    prompt_template = PromptTemplate(
        input_variables=["transcript"], template=note_generation_template
    )
    chain2 = LLMChain(llm=llm, prompt=prompt_template)

    # 這部分你把prompt換成漢字季的筆記對比 我現在先用給我其中三點來測試
    '''
    template1 = """give me three important part in this note
    % note
    {note}
    """
    prompt_template = PromptTemplate(input_variables=["note"], template=template1)
    chain3 = LLMChain(llm=llm, prompt=prompt_template)'''

    # 串起三個部分
    # chain1 跑的時間很久目前先拔掉
    overall_chain = SimpleSequentialChain(chains=[chain2], verbose=True)
    return overall_chain.run("\n".join(transcript))


def generate_note_openai(transcript: str | Sequence[str], usernote: str):
    note_generation_prompt = note_generation_template.format(
        transcript="\n".join(transcript)
    )
    response = OpenAIClient.chat.completions.create(
        model="gpt-3.5-turbo-16k",
        messages=[{"role": "user", "content": note_generation_prompt}],
        temperature=0.3,
    )
    generated_notes = response.choices[0].message.content
    return generated_notes or ''
